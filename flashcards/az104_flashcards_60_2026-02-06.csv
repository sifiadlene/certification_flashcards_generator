Front,Back,Extra,Tags
"Your organization has multiple departments that need isolated Azure resources with separate billing. Each department requires its own administrators who can only manage their department's resources. How should you structure the Azure environment?<br><br>A) Create multiple resource groups within one subscription<br>B) Create separate subscriptions per department under a management group<br>C) Use tags to separate resources in one subscription","B) Create separate subscriptions per department under a management group. Subscriptions provide billing isolation and administrative boundaries. Management groups enable centralized policy and RBAC inheritance across subscriptions.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/organize-subscriptions"">Organize Subscriptions</a>","Subscriptions provide: billing boundaries (separate invoices), resource limits (quotas per subscription), admin boundaries (isolate RBAC scopes). Resource groups (option A) share billing and subscription quotas. Tags (option C) don't provide admin isolation. Management group hierarchy: Root → Department MG → Dept Subscriptions. Assign policies at MG level (inherited by child subscriptions), assign RBAC at subscription level for department admins. Typical structure: Production subscriptions, Non-production subscriptions, Shared services subscription. Maximum: 5 free subscriptions, unlimited paid subscriptions, 10,000 management groups per tenant.",AZ-104 IdentityGovernance Subscriptions
"External partners need temporary access to specific Azure resources for a 3-month project. The solution must not require creating internal user accounts. How should you provide access?<br><br>A) Create Azure AD B2C accounts for each partner<br>B) Invite partners as Azure AD B2B guest users and assign RBAC roles<br>C) Share admin credentials with partners","B) Invite partners as Azure AD B2B guest users and assign RBAC roles. B2B enables external collaboration without creating internal accounts, partners use their own credentials, and you control access via RBAC.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/entra/external-id/what-is-b2b"">Azure AD B2B Overview</a>","B2B guest users: use their own identity (Azure AD, Microsoft account, Google, Facebook), appear in your Azure AD tenant, assignable to RBAC roles/groups. B2C (option A) is for customer-facing apps, not B2B collaboration. Shared credentials (option C) violate security best practices. Invitation flow: send invite → guest accepts → appears in directory → assign roles. Guest permissions: limited by default (can't enumerate directory), can access assigned resources only. Configure: external collaboration settings (who can invite, email domains allowed/blocked). Review access periodically with Azure AD Access Reviews. Charge: B2B guests count toward Azure AD license limits but external identities are free (up to 50K MAUs).",AZ-104 IdentityGovernance ExternalUsers
"Users forget passwords frequently and open support tickets. You need to reduce helpdesk workload while maintaining security. What should you implement?<br><br>A) Remove password requirements<br>B) Configure Self-Service Password Reset (SSPR) with MFA verification<br>C) Assign all users to IT admin group","B) Configure Self-Service Password Reset (SSPR) with MFA verification. SSPR enables users to reset passwords without helpdesk, requires verification methods (MFA, security questions, email, phone) for security.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/entra/identity/authentication/tutorial-enable-sspr"">Enable SSPR</a>","SSPR requirements: Azure AD Premium P1 license, configure authentication methods (minimum 2), enable for user group/all users. Removing passwords (option A) reduces security. IT admin (option C) grants excessive privileges. Verification methods: Mobile app notification, Mobile app code, Email, Office phone, Security questions. Require 2 methods to reset. On-premises writeback: sync new passwords to AD DS (requires Azure AD Connect with writeback enabled). Monitoring: use Azure Monitor to track SSPR events (successful resets, failed attempts, locked accounts). Configure: Authentication methods blade → SSPR → Enabled for: All/Selected users. Reduces helpdesk tickets by 30-50%.",AZ-104 IdentityGovernance SSPR
"Azure resources need to be protected from accidental deletion. Some resources like production databases must never be deleted without approval. How should you prevent deletion?<br><br>A) Use RBAC to remove delete permissions<br>B) Apply CanNotDelete or ReadOnly resource locks<br>C) Use Azure Policy to block deletion","B) Apply CanNotDelete or ReadOnly resource locks. Resource locks override RBAC permissions, prevent deletion (CanNotDelete) or modifications (ReadOnly) even by Owners.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/lock-resources"">Resource Locks</a>","Lock types: CanNotDelete (read and modify OK, delete blocked), ReadOnly (read only, no modify/delete). RBAC (option A) can be bypassed by admins with high privileges. Azure Policy (option C) audits but doesn't prevent. Lock scope: subscription, resource group, or resource level. Locks inherit: parent scope locks apply to child resources. Delete locked resource: 1) Remove lock, 2) Delete resource. Manage locks: Owner or User Access Administrator role. Use case: protect production databases, networking infrastructure, Key Vaults. Best practice: apply CanNotDelete on critical resource groups, document lock purpose in description field. Portal, CLI, PowerShell, ARM templates support locks.",AZ-104 IdentityGovernance ResourceLocks
"An organization needs to enforce naming conventions (e.g., all resource names must contain department code), allowed locations (only UK regions), and required tags (CostCenter, Environment). How should you enforce these standards?<br><br>A) Document standards and rely on manual compliance<br>B) Create and assign Azure Policy with deny effects and append modifications<br>C) Use RBAC to limit user actions","B) Create and assign Azure Policy with deny effects and append modifications. Azure Policy evaluates resources against rules, can deny non-compliant deployments, and automatically append required tags.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/governance/policy/overview"">Azure Policy Overview</a>","Policy components: policy definition (rules), assignment (scope), parameters (values). Manual standards (option A) don't enforce compliance. RBAC (option C) doesn't validate configurations. Effects: Deny (block non-compliant deployments), Append (add tags automatically), Modify (remediate non-compliant resources), Audit (log non-compliance), DeployIfNotExists (auto-deploy). Built-in policies: ""Allowed locations"", ""Require tag and its value"", ""Allowed resource types"". Custom policy example: require naming pattern with regex. Policy initiatives: group multiple policies (e.g., CIS benchmark, PCI compliance). Compliance dashboard: shows % compliant, non-compliant resources. Remediation tasks fix existing non-compliant resources.",AZ-104 IdentityGovernance AzurePolicy
"Multiple subscriptions need consistent role assignments for security teams across all current and future subscriptions. What's the most efficient approach?<br><br>A) Manually assign roles in each subscription<br>B) Create management group, assign roles at MG level with inheritance<br>C) Use Azure Automation to replicate assignments","B) Create management group, assign roles at MG level with inheritance. Management groups provide hierarchical scope for policies and RBAC, assignments inherit to child MGs and subscriptions, automatically applies to new subscriptions.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/governance/management-groups/overview"">Management Groups</a>","Management group hierarchy: Root MG (tenant-level) → Division MGs → Department MGs → Subscriptions. Manual assignment (option A) doesn't scale. Automation (option C) requires maintenance. Inheritance: RBAC assigned at parent MG applies to all children, policies assigned at MG enforce across subscriptions. Use case: Security Readers group assigned at root MG gets read access to all subscriptions. Structure: Production MG, Non-Production MG, Sandbox MG. RBAC roles: assign specific roles per MG (Security team → Security Reader at root, App teams → Contributor at dept MG). Maximum depth: 6 levels (excluding root and subscription), 10,000 MGs per tenant. Set up: Elevate Global Admin to User Access Administrator of root MG first.",AZ-104 IdentityGovernance ManagementGroups
"Azure spending exceeded budget last month. You need to prevent future overages while allowing resource deployments within budget. What should you implement?<br><br>A) Set up spending alerts only<br>B) Configure Azure budgets with action groups and alert thresholds<br>C) Manually review costs weekly","B) Configure Azure budgets with action groups and alert thresholds. Budgets track spending against thresholds (e.g., 50%, 80%, 100%), trigger alerts to action groups (email/webhook), enable proactive cost management.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/cost-management-billing/costs/tutorial-acm-create-budgets"">Create Budgets</a>","Budget configuration: set amount ($10K/month), time period (monthly/quarterly/annual), alert thresholds (50%, 90%, 100% of budget), action groups (email admins, trigger runbook). Alerts only (option A) reactive, not proactive. Manual review (option C) doesn't scale. Action groups: send emails, SMS, trigger Logic App (auto-shutdown VMs), create service ticket. Budget scopes: subscription, resource group, management group. Forecasted spending: predicts when budget will exceed based on trends. Cost recommendations: Azure Advisor identifies unused resources (idle VMs, unattached disks), right-sizing opportunities. Tags for cost allocation: assign CostCenter tag, filter by tag in cost analysis. Spending doesn't stop at budget (use limits via Azure Policy).",AZ-104 IdentityGovernance CostManagement
"A storage account contains sensitive data that must be accessible only from specific VNets and approved public IPs. How should you configure network access?<br><br>A) Keep storage account public with SAS tokens<br>B) Configure Storage firewall allowing selected VNets and IP ranges<br>C) Use NSGs to control storage access","B) Configure Storage firewall allowing selected VNets and IP ranges. Storage firewall restricts access to specified VNets (via service endpoints) and public IP ranges, denies all other traffic.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/storage/common/storage-network-security"">Storage Network Security</a>","Storage firewall settings: default allow/deny, VNet rules (subnets with Microsoft.Storage service endpoint), IP rules (public IPs, CIDR ranges), resource instance rules (specific Azure resources). SAS tokens (option A) don't restrict networks. NSGs (option C) control traffic to VMs, not storage accounts. Configuration: Networking blade → Firewalls and virtual networks → Selected networks, add VNets (requires service endpoint on subnet), add IP ranges (office IPs). Exceptions: Allow trusted MS services (Backup, Site Recovery, Log Analytics), Allow Azure portal access. Private endpoints: more secure alternative, injects storage into VNet with private IP. Test: access from unauthorized network returns 403 Forbidden. Logging: diagnostic settings track blocked requests.",AZ-104 Storage NetworkSecurity
"An application requires access to Azure storage blobs with granular permissions (read only, expiry time) without exposing storage account keys. What access method should you use?<br><br>A) Share storage account access keys<br>B) Generate Shared Access Signature (SAS) tokens with specific permissions and expiry<br>C) Make storage account public","B) Generate Shared Access Signature (SAS) tokens with specific permissions and expiry. SAS provides delegated access with specific permissions (read/write), resource scope (blob/container), time-bound validity, without sharing account keys.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview"">Shared Access Signatures</a>","SAS types: Account SAS (multiple services), Service SAS (one service), User delegation SAS (signed with Azure AD credentials, most secure). Account keys (option A) grant full access, hard to revoke. Public storage (option C) exposes all data. SAS parameters: permissions (r,w,d,l), expiry time, IP restrictions, HTTPS only. Stored access policy: define SAS parameters in container/queue, can revoke by deleting policy (without regenerating SAS). Best practices: use user delegation SAS (requires Azure AD), set short expiry (hours, not years), use HTTPS only, monitor with Azure Monitor. Generate: Azure Portal, PowerShell (New-AzStorageBlobSASToken), CLI, SDKs. Revoke: delete stored access policy or regenerate account key (affects all SAS).",AZ-104 Storage SAS
"A storage account in East US needs to be replicated to West US for disaster recovery with minimal data loss (seconds) and automatic failover capability. Which redundancy option should you configure?<br><br>A) Locally redundant storage (LRS)<br>B) Geo-redundant storage with read access (RA-GRS)<br>C) Geo-zone-redundant storage (GZRS)","C) Geo-zone-redundant storage (GZRS). GZRS replicates synchronously across 3 availability zones in primary region, then asynchronously to secondary region, provides zonal and geo redundancy with automatic failover.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/storage/common/storage-redundancy"">Storage Redundancy</a>","Redundancy options: LRS (3 copies, same datacenter, 11 nines), ZRS (3 zones, same region, 12 nines), GRS (primary + secondary region, 16 nines), GZRS (zones + geo, 16 nines), RA-GRS/RA-GZRS (read access to secondary). LRS (option A) single region only. RA-GRS (option B) requires manual failover for write access. GZRS: synchronous replication to 3 AZs (milliseconds), asynchronous to secondary (~15 min RPO). Failover types: Microsoft-managed (automatic during regional disaster), customer-managed (manual). Read-only secondary: RA-GZRS allows read from secondary during primary region issue. Change redundancy: can switch between types (GRS→GZRS, LRS→ZRS) in portal, may take up to 72 hours. Cost: LRS cheapest, GZRS most expensive.",AZ-104 Storage Redundancy
"Blob data rarely accessed after 90 days but must be stored for 7 years for compliance. The solution must minimize storage costs. How should you configure blob storage?<br><br>A) Keep all blobs in Hot tier<br>B) Implement lifecycle management policy to move blobs to Cool tier at 90 days and Archive at 180 days<br>C) Manually move blobs between tiers monthly","B) Implement lifecycle management policy to move blobs to Cool tier at 90 days and Archive at 180 days. Lifecycle policies automatically transition blobs between tiers based on rules (last modified, creation date), reducing costs without manual intervention.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview"">Blob Lifecycle Management</a>","Access tiers: Hot (frequent access, highest storage cost, lowest access cost), Cool (infrequent, 30-day minimum), Archive (offline, 180-day minimum, lowest storage cost, highest rehydration cost). Hot tier (option A) expensive for inactive data. Manual management (option C) doesn't scale. Lifecycle policy rules: apply to base blobs, snapshots, or versions; conditions based on days since modified/created; actions: move to Cool/Archive, delete. Example rule: move to Cool after 90 days idle, Archive after 180 days, delete after 7 years. Archive rehydration: hours (standard priority) or <1 hour (high priority, costlier). Set via: Portal (Lifecycle management blade), PowerShell, CLI, ARM template. Savings: Archive is 01% cost of Hot tier.",AZ-104 Storage LifecycleManagement
"Blob containers contain critical application data that users accidentally delete. You need point-in-time recovery capability. What features should you enable?<br><br>A) Blob snapshots only<br>B) Enable soft delete for blobs and containers, and blob versioning<br>C) Replicate to another storage account","B) Enable soft delete for blobs and containers, and blob versioning. Soft delete retains deleted blobs/containers for recovery period (7-365 days). Versioning maintains previous versions automatically on overwrites.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/storage/blobs/soft-delete-blob-overview"">Blob Soft Delete</a>","Soft delete: deleted blobs/containers enter deleted state, recoverable within retention period, protects against accidental deletion. Snapshots (option A) require manual creation. Replication (option C) doesn't protect against immediate deletion. Blob soft delete: configure retention days (1-365), deleted blobs shown with ""include deleted"" option, restore with Undelete. Container soft delete: prevents container deletion, must enable blob soft delete first. Versioning: creates new version on every write, previous versions retained, access specific version by ID. Combined protection: soft delete + versioning + snapshots = comprehensive data protection. Point-in-time restore: restore container to any point within retention period. Cost: soft delete and versions count toward storage costs.",AZ-104 Storage DataProtection
"Azure Files share needs to support SMB access from on-premises Windows servers with Active Directory authentication. How should you configure identity-based authentication?<br><br>A) Use storage account keys only<br>B) Enable Azure AD domain join for storage account with AD DS or Azure AD DS<br>C) Require shared access signature tokens","B) Enable Azure AD domain join for storage account with AD DS or Azure AD DS. Azure Files supports identity-based SMB access via Active Directory, enabling NTFS ACLs and Windows authentication.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/storage/files/storage-files-active-directory-overview"">Azure Files AD Authentication</a>","Identity options: on-premises AD DS (hybrid), Azure AD DS (managed), Azure AD Kerberos (cloud-only). Account keys (option A) are shared secrets, not identity-based. SAS (option C) lacks NTFS ACL support. AD DS configuration: 1) domain-join storage account to AD, 2) sync AD to Azure AD with AAD Connect, 3) assign share-level permissions (RBAC: Storage File Data SMB Share Reader/Contributor/Elevated Contributor), 4) configure directory/file-level NTFS permissions. Supported protocols: SMB 3.0+ (2.1 requires secure transfer disabled). Access from: domain-joined VMs (seamless), on-premises servers (requires line of sight to AD). Storage account has identity in AD DS. Share-level vs NTFS: share-level controls who can mount, NTFS controls file/folder access.",AZ-104 Storage AzureFiles
"A web application deployed globally needs container images stored and replicated across regions for faster pulls during deployment. What Azure service should you implement?<br><br>A) Azure Blob storage with manual replication<br>B) Azure Container Registry with geo-replication<br>C) Azure Files with global shares","B) Azure Container Registry with geo-replication. ACR Premium tier supports geo-replication, creating registry replicas in multiple regions, enabling local pulls, reducing latency and egress costs.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/container-registry/container-registry-geo-replication"">ACR Geo-Replication</a>","ACR tiers: Basic (dev/test), Standard (production), Premium (geo-replication, VNet integration, >10TB storage). Blob storage (option A) not optimized for container images. Azure Files (option C) for file shares, not containers. Geo-replication benefits: single registry name, replicas in multiple regions, local image pulls (reduced latency), single management point. Configuration: enable Premium tier, add replicas in regions (up to 10 regions), webhook notifications per region. Regional pulls: Docker/containerd automatically pulls from nearest replica. Use cases: global deployments (AKS clusters worldwide), disaster recovery (failover to replica region), reduce egress costs (pull within region is free). Cost: per replica + storage in each region. Manage: Portal, CLI (az acr replication create).",AZ-104 Compute ACR
"An ARM template needs to be deployed to create VNets and VMs. Before production deployment, you must validate the template without creating resources. How should you test the template?<br><br>A) Deploy to production and check results<br>B) Use ARM template what-if operation and validate deployment<br>C) Review template JSON manually","B) Use ARM template what-if operation and validate deployment. What-if shows predicted changes without deploying. Validate checks template syntax and parameters for errors before deployment.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/azure-resource-manager/templates/deploy-what-if"">ARM Template What-If</a>","What-if operation: shows resources to be created/modified/deleted, property changes (before/after values), no actual deployment. Production deployment (option A) risky without validation. Manual review (option C) doesn't catch all errors. Validation: checks template syntax, parameter types, resource provider availability, quota limits. Commands: az deployment group what-if, New-AzResourceGroupDeployment -WhatIf. Output colors: green (create), blue (modify), orange (delete), purple (deploy). Deployment modes: Complete (deletes resources not in template), Incremental (adds/updates only). Validate before what-if: az deployment group validate. Best practices: test in dev environment, use parameter files (dev/prod), enable deployment debugging. Export existing deployment: az group export, then modify as template.",AZ-104 Compute ARMTemplates
"Virtual machines require different availability guarantees: web tier needs 99.99% uptime across zones, backend tier needs 99.95% within zone. How should you deploy VMs?<br><br>A) Deploy all VMs to same availability set<br>B) Deploy web tier to availability zones, backend to availability set<br>C) Deploy all VMs without high availability","B) Deploy web tier to availability zones, backend to availability set. Availability zones provide 99.99% SLA (datacenter-level isolation), availability sets provide 99.95% SLA (rack-level isolation).<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/virtual-machines/availability"">VM Availability Options</a>","High availability options: Availability zones (separate datacenters in region, 99.99%, protect from datacenter failure), Availability sets (separate update/fault domains, 99.95%, protect from rack failure), Single VM with premium SSD (99.9%). Same set (option A) can't span zones. No HA (option C) only 99.9% SLA. Availability set: update domains (5 default, VMs reboot sequentially), fault domains (2-3, separate power/network). Zone deployment: specify zone 1/2/3, manually distribute VMs across zones. Trade-offs: zones = higher SLA but inter-zone latency, sets = lower SLA but same-DC latency. Best practice: stateless web tier (zones), stateful DB tier (zone redundant storage). Cost: no additional charge for HA, only for VMs. Can't convert existing VM between zones (must redeploy).",AZ-104 Compute VMAvailability
"A VM uses managed disks and needs encrypted at-rest data without guest OS configuration. The encryption keys must be customer-managed. What encryption option should you use?<br><br>A) Azure Disk Encryption (BitLocker/DM-Crypt in guest OS)<br>B) Server-Side Encryption with customer-managed keys (SSE with CMK)<br>C) Encryption at host","B) Server-Side Encryption with customer-managed keys (SSE with CMK). SSE encrypts data at Azure storage platform level, uses keys from Key Vault, no guest OS configuration required, enabled by default with platform-managed keys.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/virtual-machines/disk-encryption"">Managed Disk Encryption</a>","Encryption options: SSE (storage platform encryption, enabled by default), ADE (guest OS encryption, requires VM extension), Encryption at host (host-level encryption). ADE (option A) requires guest OS changes and VM extension. Encryption at host (option C) requires specific VM sizes. SSE with CMK: create Key Vault, create encryption key (KEK), create disk encryption set referencing key, assign managed identity to disk encryption set, grant Key Vault permissions, create disk with encryption set. Key rotation: update key version in Key Vault, disk encryption set automatically uses new version. Comparison: SSE = transparent, no guest impact; ADE = guest-level control, supports Linux/Windows. Both can coexist (double encryption). CMK vs PMK: management overhead vs simplicity. Supports: OS disks, data disks, snapshots, images.",AZ-104 Compute DiskEncryption
"A web application experiences unpredictable traffic spikes. You need automatic scaling based on CPU utilization while controlling costs. What should you implement?<br><br>A) Manually resize VMs during traffic spikes<br>B) Deploy Virtual Machine Scale Set with autoscale rules based on metrics<br>C) Over-provision VMs for peak load permanently","B) Deploy Virtual Machine Scale Set with autoscale rules based on metrics. VMSS automatically increases/decreases VM instances based on metrics (CPU, memory, custom) or schedule, optimizes cost and performance.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-autoscale-overview"">VMSS Autoscale</a>","VMSS benefits: identical VMs from common image, automatic scaling (0-1000 instances), load balancer integration, availability zone distribution. Manual resizing (option A) doesn't scale. Over-provisioning (option C) wastes money. Autoscale rules: scale out (add instances) when CPU >75% for 10 min, scale in (remove instances) when CPU <25% for 10 min. Conditions: metric-based (CPU, memory, network, custom), schedule-based (business hours), combine multiple rules. Limits: minimum instances (2), maximum instances (10), default instances (2). Cooldown period: 5 min between scale operations (prevents flapping). Load balancer: Azure Load Balancer (L4) or Application Gateway (L7) distributes traffic. Upgrade policy: automatic, rolling, manual. Cost optimization: use scale-in manually, schedule scale-down for nights.",AZ-104 Compute VMSS
"Container applications need orchestration, automatic restarts on failure, and external connectivity. The solution must be simple without Kubernetes complexity. What should you use?<br><br>A) Azure Kubernetes Service for full orchestration<br>B) Azure Container Instances with container groups and restart policies<br>C) Azure Container Apps with microservices support","C) Azure Container Apps with microservices support. Container Apps provides managed container hosting with automatic scaling, built-in ingress, service discovery, and Dapr integration, simpler than AKS.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/container-apps/overview"">Container Apps Overview</a>","Container hosting options: ACI (simple single containers, no orchestration), Container Apps (microservices, autoscaling, ingress), AKS (full Kubernetes, most complex). AKS (option A) overkill for simple apps. ACI (option B) limited orchestration. Container Apps features: HTTP/TCP ingress, automatic scaling (0-30 replicas based on HTTP/CPU), background jobs, Dapr integration (pub-sub, state), VNet integration, managed certificates. Deployment: define container (image, resources), configure scaling rules (HTTP concurrency, CPU, custom), set ingress (internal/external). Revisions: deploy new version, split traffic (blue-green), rollback. Use cases: web APIs, background workers, event-driven processing. Pricing: vCPU-seconds + memory GiB-seconds, scale-to-zero saves costs. VS AKS: Container Apps = serverless simplicity, AKS = full K8s control.",AZ-104 Compute ContainerApps
"An App Service web app experiences high load during business hours (8 AM - 6 PM) but low traffic at night. You need to optimize costs while maintaining performance. How should you configure scaling?<br><br>A) Use Premium P1V2 tier permanently<br>B) Configure autoscale with schedule-based rules (scale up during business hours, scale down at night)<br>C) Use consumption tier","B) Configure autoscale with schedule-based rules (scale up during business hours, scale down at night). Schedule-based autoscale changes instance count based on time, optimizes cost without sacrificing performance during peak hours.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/app-service/manage-scale-up"">App Service Scaling</a>","Scaling directions: scale up (change tier, more CPU/RAM), scale out (add instances, handle more requests). Premium (option A) constant cost. Consumption (option C) for Functions, not App Service. Autoscale rules: schedule-based (M-F 8 AM-6 PM use 3 instances, nights/weekends 1 instance), metric-based (CPU >70% → add instance), combine both. Requirements: Standard tier or higher for autoscale, Basic/Free don't support autoscale. Settings: minimum instances (1), maximum instances (10), default instances (2), cooldown (5 min). Best practices: use deployment slots for zero-downtime deployments, enable diagnostics logging, monitor with Application Insights. Scale up scenarios: need more CPU/memory/storage, add deployment slots (Standard+), add VNet integration (Premium+). Sudden traffic: pre-scale using schedule before expected spike.",AZ-104 Compute AppServiceScaling
"An App Service web app needs to support custom domain (www.contoso.com) with TLS encryption. What configuration steps are required?<br><br>A) Custom domains aren't supported in App Service<br>B) Add custom domain, upload/import TLS certificate, create TLS/SSL binding<br>C) Use Azure CDN only","B) Add custom domain, upload/import TLS certificate, create TLS/SSL binding. App Service supports custom domains with managed certificates (free) or imported certificates, enables HTTPS.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/app-service/app-service-web-tutorial-custom-domain"">Custom Domain Configuration</a>","Custom domain steps: 1) Get domain from registrar, 2) Create DNS records (A or CNAME pointing to app, TXT for verification), 3) Add custom domain in App Service, 4) Validate domain ownership, 5) Create TLS binding. Custom domains (option A) fully supported. CDN (option C) optional for performance. Domain types: root domain (contoso.com, use A record + TXT), subdomain (www.contoso.com, use CNAME). Certificate options: App Service Managed Certificate (free, auto-renewed, standard TLS), Import certificate (pfx file, requires password), Key Vault certificate. TLS versions: require TLS 1.2 minimum. SNI SSL vs IP SSL: SNI (free, most apps), IP (dedicated IP, older clients). Wildcard certificates: *.contoso.com covers all subdomains. Requirements: Basic tier or higher for custom domains, Standard+ for SSL.",AZ-104 Compute CustomDomain
"Production App Service requires zero-downtime deployments with ability to test new version before full rollout. What deployment strategy should you implement?<br><br>A) Deploy directly to production slot<br>B) Use deployment slots with staging slot, test, then swap to production<br>C) Create separate App Service for each version","B) Use deployment slots with staging slot, test, then swap to production. Deployment slots are separate environments (staging, production), enable testing new versions, swap operation is instantaneous with zero downtime.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/app-service/deploy-staging-slots"">Deployment Slots</a>","Deployment slots: independent instances with own hostname (app-staging.azurewebsites.net), share same App Service plan, Standard tier+ required (5 slots). Direct deployment (option A) causes downtime. Separate App Service (option C) doubles cost. Workflow: 1) Deploy to staging slot, 2) Test in staging (custom domain, smoke tests), 3) Swap staging→production (instant, no downtime), 4) Rollback by swapping back if issues. Swap operation: swaps configuration (app settings, connection strings), warms up instances (pre-pings URLs), zero downtime. Slot-specific settings: mark settings as ""slot settings"" to prevent swap. Auto-swap: automatically swap after deployment (for CI/CD). Traffic routing: route % of traffic to slot for A/B testing (20% production, 80% staging). Swap preview: validate changes before completing swap.",AZ-104 Compute DeploymentSlots
"Multiple VNets in different regions need to communicate privately. The solution must support transitive connectivity through a hub VNet. How should you configure connectivity?<br><br>A) Configure VNet peering with ""use remote gateway"" and ""allow gateway transit""<br>B) Use VPN gateways between each VNet pair<br>C) Use public IPs for inter-VNet communication","A) Configure VNet peering with ""use remote gateway"" and ""allow gateway transit"". Peering enables private connectivity, gateway transit allows spokes to use hub's VPN/ExpressRoute gateway for transitivity.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-peering-overview"">VNet Peering</a>","VNet peering: private connectivity over Azure backbone, low latency, no encryption (use NSG/app-level encryption if needed), supports cross-region (global peering). VPN gateways (option B) add complexity and cost. Public IPs (option C) expose traffic to internet. Peering configuration: create peering in both directions (bidirectional), allow forwarded traffic (hub-spoke), allow gateway transit (hub), use remote gateway (spoke). Hub-spoke topology: hub has VPN Gateway, spokes peer to hub with ""use remote gateway"", enables spoke-to-on-premises via hub gateway. Limitations: no transitive peering (spoke-to-spoke requires hub NVA or explicit peering), max 500 peerings per VNet. Traffic: not metered within same region, charged for cross-region. Service chaining: use hub NVA with UDRs for spoke-to-spoke communication.",AZ-104 Networking VNetPeering
"A VNet subnet hosts VMs that should communicate with Azure SQL Database but not access the internet. How should you configure routing?<br><br>A) Keep default routing and rely on NSGs<br>B) Create user-defined route (UDR) with 0.0.0.0/0 to None (blackhole internet), use service endpoints for SQL<br>C) Use VPN Gateway for routing","B) Create user-defined route (UDR) with 0.0.0.0/0 to None (blackhole internet), use service endpoints for SQL. UDR overrides default route, blackholes internet traffic, service endpoints enable direct Azure backbone access to SQL.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-udr-overview"">User-Defined Routes</a>","UDR components: route table (collection of routes), routes (address prefix, next hop type). NSGs only (option A) filter traffic but don't route. VPN Gateway (option C) for on-premises connectivity. Next hop types: Virtual appliance (NVA), VNet gateway (VPN/ExpressRoute), Virtual network (VNet local), Internet, None (blackhole). Use case: force internet traffic through firewall (0.0.0.0/0 → firewall IP), disable internet (0.0.0.0/0 → None), force SQL traffic over service endpoint. Service endpoints: enable on subnet (Microsoft.Sql), traffic to SQL uses Azure backbone, faster and secured. Associate UDR: apply route table to subnet. Route priority: most specific prefix wins (172.16.0.0/16 > 0.0.0.0/0). Effective routes: Portal shows computed routes including user, system, BGP routes.",AZ-104 Networking UDR
"VMs in a subnet need distinct security rules based on application tier (web, app, database). Creating individual NSG rules per VM doesn't scale. How should you simplify NSG management?<br><br>A) Create one large NSG with 100+ rules<br>B) Use Application Security Groups and reference ASGs in NSG rules<br>C) Assign NSGs per network interface","B) Use Application Security Groups and reference ASGs in NSG rules. ASGs group VMs logically (WebASG, AppASG, DbASG), NSG rules reference ASGs instead of IPs, scales elegantly as VMs are added/removed.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/virtual-network/application-security-groups"">Application Security Groups</a>","ASG benefits: logical grouping (not tied to IPs/subnets), simplify NSG rules (source/dest = ASG), scale without rule changes (add VM to ASG). Large NSG (option A) hard to manage. Per-NIC NSG (option C) doesn't leverage grouping. Configuration: 1) Create ASGs (WebASG, AppASG, DbASG), 2) Assign VMs to ASGs (NIC level), 3) Create NSG rules referencing ASGs (allow WebASG → AppASG:443, allow AppASG → DbASG:1433). Rule example: ""Priority 100, Source: WebASG, Destination: AppASG, Port: 443, Allow"". Limitations: ASG must be in same region as NSG, can't span VNets (use peering). Each NIC can belong to multiple ASGs. Zero-trust micro-segmentation: deny all by default, explicit allows between ASGs. Combine with NSG flow logs for traffic analysis.",AZ-104 Networking ASG
"Internet-facing web application on Azure VMs needs Layer 7 load balancing, SSL termination, and WAF protection. What load balancing solution should you implement?<br><br>A) Azure Load Balancer (basic SKU)<br>B) Application Gateway with WAF enabled<br>C) Traffic Manager for DNS load balancing","B) Application Gateway with WAF enabled. Application Gateway provides Layer 7 (HTTP/HTTPS) load balancing, SSL offload/termination, WAF for OWASP protection, URL-based routing, ideal for web apps.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/application-gateway/overview"">Application Gateway Overview</a>","Load balancing options: Load Balancer (L4, TCP/UDP), Application Gateway (L7, HTTP/HTTPS), Traffic Manager (DNS, global), Front Door (global L7). Load Balancer basic (option A) is L4, no SSL/WAF. Traffic Manager (option C) is DNS-based, not L7. Application Gateway features: SSL termination (decrypt on gateway, reduce VM load), WAF (OWASP rules, protect from exploits), URL routing (path-based, host-based), autoscaling, zone redundancy. SKUs: Standard_v2 (L7 load balancing), WAF_v2 (includes WAF). Backend pool: VMs, VMSS, IP address, FQDN. Routing: basic (round-robin), URL path (/images→storageVMs, /api→apiVMs), multi-site (contoso.com, fabrikam.com different backends). Health probes: check backend availability. Use with: VNet, NSG, public/private IP.",AZ-104 Networking AppGateway
"A global web application needs to route users to nearest region, automatic failover during region failure, and Layer 7 routing capabilities. What Azure service provides this?<br><br>A) Azure Front Door for global L7 load balancing and CDN<br>B) Traffic Manager for DNS-based routing<br>C) Application Gateway in one region","A) Azure Front Door for global L7 load balancing and CDN. Front Door provides global HTTP/HTTPS load balancing, SSL offload, CDN capabilities, automatic regional failover, and web application firewall.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/frontdoor/front-door-overview"">Azure Front Door</a>","Global routing options: Front Door (L7, anycast, SSL offload, WAF, CDN), Traffic Manager (L4, DNS-based, slower failover). Traffic Manager (option B) uses DNS (longer TTL, slower failover). Application Gateway (option C) is regional. Front Door features: anycast IP (clients connect to nearest edge), SSL termination (reduce backend load), URL routing (path-based), session affinity (cookie-based), WAF at edge, cache static content (CDN). Routing methods: latency (lowest latency backend), priority (primary-secondary failover), weighted (distribute %, A/B testing), session affinity. Backend pool health: active probes, automatic failover to healthy regions (seconds). Use cases: global app (VMs/App Services in multiple regions), API gateway (route to backends based on URL), content delivery (cache at edge). SSL: upload custom cert or use managed cert. Cost: per GB processed + routing rules.",AZ-104 Networking FrontDoor
"A company needs custom DNS resolution in Azure (e.g., internal.contoso.com) with name resolution across VNets. What DNS solution should you implement?<br><br>A) Use Azure-provided DNS only (168.63.129.16)<br>B) Deploy Azure Private DNS zones with VNet links<br>C) Deploy VMs as DNS servers","B) Deploy Azure Private DNS zones with VNet links. Private DNS zones provide custom DNS resolution without managing DNS servers, VNet links enable cross-VNet name resolution, auto-registration for VMs.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/dns/private-dns-overview"">Azure Private DNS</a>","DNS options: Azure-provided (VM.VNet.region.cloudapp.internal, no custom names), Private DNS zones (custom names, no infrastructure), Custom DNS servers (VMs, full control but management overhead). Azure-provided only (option A) doesn't support custom domains. DNS VMs (option C) require management. Private DNS zone: create zone (contoso.internal), link to VNets (manual registration or auto-registration), records auto-created for VMs. Record types: A (IPv4), AAAA (IPv6), CNAME (alias), MX (mail), TXT (verification). Auto-registration: VMs in linked VNets auto-register A records (VM1.contoso.internal), updates on IP change, deletes on VM deletion. Cross-VNet resolution: link zone to multiple VNets, all VNets can resolve records. Cost: per zone + per million queries (low cost). Use with: VPN Gateway (link to on-premises), peering (cross-VNet resolution), Private Endpoints (auto DNS integration).",AZ-104 Networking DNS
"Network connectivity between VMs is broken. You need to diagnose if traffic is being blocked by NSG rules. What tool should you use?<br><br>A) Network Performance Monitor<br>B) Network Watcher NSG Flow Logs and IP flow verify<br>C) Azure Monitor metrics only","B) Network Watcher NSG Flow Logs and IP flow verify. IP flow verify tests if packet is allowed/denied by NSG rules, specifying source/dest IP and port. Flow logs capture all traffic for analysis.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/network-watcher/network-watcher-ip-flow-verify-overview"">IP Flow Verify</a>","Network Watcher tools: IP flow verify (test if traffic allowed), NSG flow logs (capture all traffic), Connection Monitor (monitor connectivity), Packet capture (detailed traffic capture), Next hop (routing diagnosis). NPM (option A) monitors performance, not blocks. Azure Monitor (option C) lacks packet details. IP flow verify: specify VM, NIC, direction (inbound/outbound), protocol (TCP/UDP), IPs, port → result shows Allow/Deny + which NSG rule. NSG flow logs: enable on NSG, logs sent to Storage account, shows allowed/denied flows with tuple (src IP, dest IP, port, protocol, NSG decision). Traffic Analytics: visualizes flow logs, shows top talkers, geographic traffic, malicious IPs. Connection Monitor: continuous monitoring between VMs (on-premises, Azure, internet), alerts on connectivity loss. Troubleshoot: check Effective Security Rules → IP flow verify → NSG flow logs → adjust rules.",AZ-104 Networking Troubleshooting
"Azure Monitor needs to collect custom performance metrics from VMs (CPU, memory, disk) and application logs. What monitoring agent should you deploy?<br><br>A) No agent required, Azure Monitor collects automatically<br>B) Install Azure Monitor Agent (AMA) and configure Data Collection Rules<br>C) Use Log Analytics workspace without agents","B) Install Azure Monitor Agent (AMA) and configure Data Collection Rules. AMA replaces legacy agents (MMA, OMS), collects logs/metrics from VMs, uses DCRs to specify what data to collect and where to send.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/azure-monitor/agents/azure-monitor-agent-overview"">Azure Monitor Agent</a>","Agent options: Azure Monitor Agent (AMA, current), Log Analytics agent (MMA/OMS, deprecated 2024), Diagnostics extension (limited use). Automatic collection (option A) limited to host metrics. Workspace without agents (option C) doesn't collect guest OS data. AMA benefits: single agent for all data types, DCR-based targeting (flexible), improved security (managed identity), Windows Event Filtering (reduce data). Data Collection Rules (DCR): specify data sources (perf counters, Windows/Linux logs, IIS logs), destinations (Log Analytics workspace, Azure Monitor Metrics), associate with VMs/scale sets. Deployment: Azure Portal (Monitoring → Agents), Azure Policy (auto-deploy), VM extensions. Data types: performance counters (CPU, memory, disk), Windows event logs (System, Application), Syslog (Linux), custom logs (app-specific). Cost: data ingestion + retention in workspace.",AZ-104 Monitoring AzureMonitor
"Virtual machines experience performance degradation. You need to create alerts when CPU exceeds 85% for 15 minutes and automatically notify the operations team. How should you configure monitoring?<br><br>A) Manually check Azure Monitor metrics daily<br>B) Create metric alert rule with threshold 85%, action group with email/SMS notification<br>C) Use Azure Advisor recommendations only","B) Create metric alert rule with threshold 85%, action group with email/SMS notification. Alert rules monitor metrics, evaluate conditions, trigger action groups (notifications, webhooks, runbooks) when violated.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/azure-monitor/alerts/alerts-overview"">Azure Monitor Alerts</a>","Alert types: metric alerts (numeric thresholds), log query alerts (KQL queries), activity log alerts (ARM operations). Manual checking (option A) doesn't scale. Advisor (option C) provides recommendations, not real-time alerts. Alert rule: scope (VM ID), condition (CPU >85% for 15 min), evaluation frequency (every 1 min), action group (notifications/actions). Action groups: email (user@contoso.com), SMS (phone), voice call, Azure app push notification, webhook (trigger external system), automation runbook (auto-remediate), Logic App, Azure Function. Common metric alerts: CPU percentage, available memory, disk space, network in/out. Aggregation: average, min, max, total, count over time period. Multiple conditions: AND/OR logic (CPU >85% AND memory <20%). Severity: Critical (0), Error (1), Warning (2), Informational (3-4). Best practice: test action groups before production.",AZ-104 Monitoring Alerts
"Application issues require detailed log analysis. You need to query logs to find errors, identify patterns, and create custom views. What query language should you use in Azure Monitor?<br><br>A) SQL queries<br>B) Kusto Query Language (KQL) in Log Analytics<br>C) PowerShell commands","B) Kusto Query Language (KQL) in Log Analytics. KQL is optimized for log analytics, supports filtering, aggregation, joins, time-series analysis, visualizations, ideal for querying Azure Monitor Logs.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/azure-monitor/logs/log-query-overview"">Log Queries</a>","Query language: KQL (similar to SQL, optimized for logs). SQL (option A) not supported in Log Analytics. PowerShell (option C) for automation, not querying logs. KQL basics: table | where condition | summarize aggregation | project columns. Example: Event | where TimeGenerated > ago(1h) | where EventLevelName == ""Error"" | summarize count() by Computer. Common operators: where (filter), project (select columns), summarize (aggregate), join (combine tables), sort, top, extend (calculated columns). Time functions: ago(1d) (last 24h), between (start-end), bin (time buckets for charts). Tables: Event (Windows events), Syslog (Linux logs), Perf (performance counters), Heartbeat (VM health). Query scope: workspace, multiple workspaces, Application Insights. Visualizations: render timechart, barchart, piechart. Save queries: function (reusable), save to dashboard, export results. Alerts: create alert from query (fire when conditions met).",AZ-104 Monitoring KQL
"Azure VMs and App Services need centralized backup with 30-day retention, weekly backups, and ability to restore to specific point in time. What Azure service should you configure?<br><br>A) Manual VM snapshots only<br>B) Azure Backup with Recovery Services vault and backup policies<br>C) Export data to Storage account weekly","B) Azure Backup with Recovery Services vault and backup policies. Recovery Services vault stores backups centrally, backup policies define schedule/retention, supports VMs, databases, files, point-in-time recovery.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/backup/backup-overview"">Azure Backup Overview</a>","Backup service: Recovery Services vault (VMs, databases, files, Site Recovery), Backup vault (newer, supports disks, blobs, AKS). Manual snapshots (option A) require management. Storage export (option C) not a backup solution. Backup policy: schedule (daily, weekly), retention (30 days daily, 12 weeks weekly, 12 months monthly, 10 years yearly), instant restore (2 days for quick recovery). Supported workloads: Azure VMs, SQL Server in VMs, SAP HANA, Azure Files, on-premises (MARS agent), Blob backup (operational/vaulted). VM backup process: snapshot VM disks, transfer to vault, retention per policy. Restore options: create new VM, replace disks, restore files from backup. Backup reports: Azure Monitor for compliance, backup trends, storage consumed. Cost: protected instances + storage consumed. Soft delete: 14-day retention for deleted backups (ransomware protection). Cross-region restore: restore in secondary region (GRS/RA-GRS vaults).",AZ-104 Monitoring Backup
"Disaster recovery plan requires VMs in East US to fail over to West US during regional outage. The solution must provide automated failover and minimal data loss. What should you implement?<br><br>A) Manually recreate VMs in secondary region during disaster<br>B) Configure Azure Site Recovery replication to secondary region with recovery plans<br>C) Use Azure Backup restore in secondary region","B) Configure Azure Site Recovery replication to secondary region with recovery plans. Site Recovery continuously replicates VMs to target region, enables automated failover with orchestrated recovery plans, provides low RPO/RTO.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/site-recovery/site-recovery-overview"">Azure Site Recovery</a>","DR solutions: Site Recovery (VM replication, orchestrated failover), Backup (point-in-time restore, higher RTO). Manual recreation (option A) high RTO. Backup restore (option C) slower than replication. Site Recovery features: continuous replication (app-consistent, 30-sec snapshots), recovery plans (multi-VM failover sequence, scripts), test failover (validate without impacting production), replication policy (retention 24h-72h). Configuration: create Recovery Services vault in target region, enable replication per VM (or bulk), select target region, configure network mapping (source VNet → target VNet). Replication: initial copy (full data) then delta changes continuously. Failover types: test (non-disruptive validation), planned (zero data loss, source shutdown first), unplanned (source unavailable). Recovery point objectives: RPO (app-consistent: 60 min, crash-consistent: 5 min). Re-protect: after failover, re-protect from target→source for failback. Cost: per protected instance + egress for replication data.",AZ-104 Monitoring SiteRecovery