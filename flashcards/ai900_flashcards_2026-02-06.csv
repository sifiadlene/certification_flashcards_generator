Front,Back,Extra,Tags
"A retail company wants to analyze customer reviews to understand overall sentiment and identify commonly mentioned product features. Which AI workload best describes this scenario?<br><br>A) Computer vision for image analysis<br>B) Natural language processing for text analytics<br>C) Machine learning for predictive modeling","B) Natural language processing for text analytics. NLP workloads analyze text data to extract meaning, sentiment, entities, and key phrases from written content like customer reviews.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/language-service/overview"">Azure AI Language Overview</a>","NLP encompasses sentiment analysis (positive/negative/neutral), key phrase extraction (important topics), and entity recognition (product names, features). Computer vision (option A) analyzes images/video, not text. Machine learning (option C) is the underlying technology but doesn't specify the text analysis workload. Common NLP tasks include: text classification, translation, question answering, conversational understanding.",AI-900 AIWorkloads NLP
"Your organization is building an AI solution that must treat all users fairly regardless of gender, age, or ethnicity. Which responsible AI principle does this primarily address?<br><br>A) Transparency<br>B) Fairness<br>C) Reliability and safety","B) Fairness. The fairness principle ensures AI systems treat all people equitably and avoid affecting similarly situated groups of people in different ways.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai"">Responsible AI Principles</a>","Fairness addresses bias and discrimination in AI systems. Evaluate models for disparate impact across demographic groups. Transparency (option A) is about explainability. Reliability (option C) is about consistent performance. Other responsible AI principles: Privacy & Security, Inclusiveness (designing for everyone), Accountability (taking responsibility for AI decisions). Use tools like Fairness dashboards to detect and mitigate bias in training data and model predictions.",AI-900 ResponsibleAI Fairness
"A machine learning model predicts house prices based on features like square footage, number of bedrooms, and location. What type of machine learning technique is this?<br><br>A) Regression<br>B) Classification<br>C) Clustering","A) Regression. Regression predicts a continuous numeric value (price) based on input features. It establishes relationships between variables to forecast numeric outcomes.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml"">Machine Learning Tasks</a>","Regression outputs numeric values: prices, temperatures, sales figures. Classification (option B) predicts categories/labels (spam/not spam, cat/dog). Clustering (option C) groups similar data without labels. Common regression algorithms: linear regression, decision trees, random forests. Evaluation metrics for regression: RMSE (Root Mean Square Error), MAE (Mean Absolute Error), R² (coefficient of determination). Use regression when your target variable is continuous and numeric.",AI-900 MachineLearning Regression
"A medical diagnosis system needs to categorize patient X-rays as showing pneumonia, tuberculosis, or healthy lungs. What machine learning technique should be used?<br><br>A) Regression to predict disease probability<br>B) Classification to assign category labels<br>C) Clustering to find similar X-ray patterns","B) Classification to assign category labels. Classification assigns data to predefined categories or classes. In this case, the model classifies X-rays into one of three classes: pneumonia, tuberculosis, or healthy.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml"">Automated ML Task Types</a>","Classification outputs discrete categories/labels. Binary classification has 2 classes (positive/negative), multiclass has 3+ classes (this scenario). Regression (option A) predicts numbers, not categories. Clustering (option C) finds patterns without predefined labels. Common classification algorithms: logistic regression, decision trees, neural networks. Evaluation metrics: accuracy, precision, recall, F1-score, confusion matrix. Classification is supervised learning (requires labeled training data).",AI-900 MachineLearning Classification
"A customer segmentation project analyzes purchase history to group customers with similar buying behaviors without predefined categories. Which machine learning technique is this?<br><br>A) Supervised learning with labeled customer types<br>B) Unsupervised learning with clustering algorithms<br>C) Reinforcement learning with reward optimization","B) Unsupervised learning with clustering algorithms. Clustering groups similar data points without predefined labels, discovering natural patterns in data. It's unsupervised because there are no labeled examples to learn from.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml#clustering"">Clustering in Azure ML</a>","Clustering finds inherent groupings in unlabeled data. Common algorithms: K-means, DBSCAN, hierarchical clustering. Supervised learning (option A) requires labeled training data. Reinforcement learning (option C) learns through trial-and-error with rewards. Clustering is useful for: customer segmentation, anomaly detection, data exploration. No ""correct"" answer exists in clustering; evaluate using silhouette scores, elbow method. Results show which customers have similar characteristics (spending patterns, product preferences).",AI-900 MachineLearning Clustering
"In machine learning, what is the purpose of splitting data into training and validation datasets?<br><br>A) Training data teaches patterns; validation data tests if learning generalizes to new data<br>B) Training data stores all examples; validation data backs up the training set<br>C) Training data contains features; validation data contains labels","A) Training data teaches patterns; validation data tests if learning generalizes to new data. Training data is used to fit the model, while validation data evaluates performance on unseen data to detect overfitting.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-train-machine-learning-model"">Train ML Models</a>","Typical split: 70-80% training, 10-15% validation, 10-15% test. Training data teaches the model patterns. Validation data tunes hyperparameters and assesses generalization. Test data provides final evaluation. Overfitting occurs when model memorizes training data but fails on new data. Underfitting happens when model is too simple. Validation helps find the sweet spot. Cross-validation uses multiple validation sets for robust evaluation. Both datasets contain features AND labels (for supervised learning).",AI-900 MachineLearning DataSplitting
"What Azure service provides automated machine learning capabilities to automatically try multiple algorithms and hyperparameters to find the best model?<br><br>A) Azure Machine Learning Automated ML<br>B) Azure AI Vision custom models<br>C) Azure Cognitive Services","A) Azure Machine Learning Automated ML. Automated ML (AutoML) automatically tries multiple algorithms, feature engineering techniques, and hyperparameters to find the optimal model for your data and task.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml"">Automated ML Overview</a>","AutoML democratizes ML by handling algorithm selection, preprocessing, feature engineering, and hyperparameter tuning. Supports classification, regression, time-series forecasting. Provides model explainability and featurization transparency. AI Vision (option B) is for computer vision, not general ML. Cognitive Services (option C) are prebuilt AI capabilities. AutoML saves data scientists weeks of experimentation. Outputs best model with performance metrics and explanations. Integrates with Azure ML Studio for no-code/low-code experience.",AI-900 AzureML AutomatedML
"An image classification model needs to identify whether photos contain cats, dogs, or birds. What are the ""labels"" in this scenario?<br><br>A) The pixel values of each image<br>B) The categories: cat, dog, bird<br>C) The image file names","B) The categories: cat, dog, bird. Labels are the target values or outcomes the model learns to predict. In classification, labels are the categories or classes each data item belongs to.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-data-labeling"">Data Labeling Concepts</a>","In supervised learning: Features are input data (pixel values, image characteristics), Labels are outputs to predict (categories). For this task: Features = image pixels/characteristics, Labels = cat/dog/bird. File names (option C) are metadata, not labels. Labeled data is required for supervised learning. Data labeling projects involve humans annotating examples. One-hot encoding represents labels as binary vectors: cat=[1,0,0], dog=[0,1,0], bird=[0,0,1]. Quality labels are critical for model accuracy.",AI-900 MachineLearning FeaturesLabels
"A company wants to deploy a trained machine learning model to a REST API endpoint for real-time predictions. Which Azure Machine Learning capability enables this?<br><br>A) Model training with compute clusters<br>B) Model deployment to managed endpoints<br>C) Automated machine learning experiments","B) Model deployment to managed endpoints. Azure ML enables deploying trained models as web services (REST APIs) on managed endpoints for real-time or batch inference.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-endpoints"">Endpoints in Azure ML</a>","Deployment options: Real-time endpoints (low latency, individual predictions), Batch endpoints (high throughput, batch scoring). Managed endpoints handle infrastructure, scaling, security. Training (option A) creates models, not deployment. AutoML (option C) finds best models. After training, register model in Azure ML registry, create endpoint, deploy model version, test with sample data. Supports A/B testing with traffic splitting. Monitor with Application Insights. Managed endpoints provide authentication, SSL, auto-scaling.",AI-900 AzureML Deployment
"Which computer vision task identifies and locates multiple objects within an image by drawing bounding boxes around them?<br><br>A) Image classification<br>B) Object detection<br>C) Optical character recognition","B) Object detection. Object detection identifies multiple objects in an image, determines their type/class, and locates them using bounding boxes with coordinates.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-object-detection"">Object Detection</a>","Object detection outputs: class labels + bounding box coordinates (x, y, width, height) for each object. Can detect multiple objects of different types in one image. Image classification (option A) assigns one label to entire image without location. OCR (option C) extracts text, not objects. Common uses: inventory counting, safety monitoring, autonomous vehicles. Algorithms: YOLO, R-CNN, SSD. Outputs confidence scores per detection. Azure Custom Vision supports custom object detection models.",AI-900 ComputerVision ObjectDetection
"A mobile banking app needs to extract text from photos of checks (account numbers, amounts, signatures). What computer vision capability is required?<br><br>A) Image classification to categorize check types<br>B) Object detection to find checks in photos<br>C) Optical character recognition to read text","C) Optical character recognition to read text. OCR extracts printed or handwritten text from images, converting visual text into machine-readable text that can be processed.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-ocr"">OCR in Azure AI Vision</a>","OCR (Optical Character Recognition) converts image text to digital text. Azure AI Vision Read API handles printed and handwritten text in 100+ languages. Returns extracted text with bounding boxes and confidence scores. Classification (option A) categorizes images, doesn't extract text. Object detection (option B) finds objects, not text characters. Use cases: document digitization, receipt processing, license plate reading. Form Recognizer (Document Intelligence) combines OCR with structure extraction for forms/documents. Read API optimized for text-heavy documents.",AI-900 ComputerVision OCR
"An app needs to detect faces in photos and estimate age, emotion, and whether the person is wearing glasses. Which Azure service provides these capabilities?<br><br>A) Azure AI Vision for general image analysis<br>B) Azure AI Face for facial detection and analysis<br>C) Azure Custom Vision for custom face models","B) Azure AI Face for facial detection and analysis. Azure AI Face detects human faces and analyzes facial attributes including age, emotion, accessories, facial landmarks, and identification.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-identity"">Face Detection and Analysis</a>","Azure AI Face capabilities: Face detection (location/bounding box), Face attributes (age, emotion, glasses, facial hair, makeup), Face landmarks (27 points), Face recognition (identification/verification). Returns confidence scores. Emotions detected: happiness, sadness, anger, surprise, fear, contempt, disgust, neutral. AI Vision (option A) has basic face detection but limited attributes. Custom Vision (option C) is for training custom image models, not specialized face analysis. Consider responsible AI: obtain consent, avoid bias, handle sensitive data properly.",AI-900 ComputerVision FaceDetection
"What Azure AI service would you use to extract insights and metadata from videos, including scene detection, celebrities, keywords, and transcript generation?<br><br>A) Azure AI Vision for image analysis on video frames<br>B) Azure AI Video Indexer for comprehensive video analysis<br>C) Azure Media Services for video streaming","B) Azure AI Video Indexer for comprehensive video analysis. Video Indexer extracts rich insights from videos including faces, speakers, transcripts, keywords, scene changes, brand mentions, and emotions.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/azure-video-indexer/video-indexer-overview"">Video Indexer Overview</a>","Video Indexer provides 25+ insights: transcription (speech-to-text), translation, face detection, celebrity recognition, keyword extraction, sentiment analysis, topics, scene segmentation, OCR in video, brand detection, content moderation. AI Vision (option A) analyzes still images. Media Services (option C) handles video encoding/streaming, not AI analysis. Supports 50+ languages. Outputs timeline with searchable insights. Use cases: media libraries, content moderation, accessibility (captions), e-learning. Portal and REST API available.",AI-900 ComputerVision VideoAnalysis
"A global e-commerce site needs to translate product descriptions from English into 50 languages. Which Azure AI capability should be used?<br><br>A) Azure AI Translator for text translation<br>B) Azure AI Language for sentiment analysis<br>C) Azure AI Speech for speech translation","A) Azure AI Translator for text translation. Azure AI Translator provides text translation across 100+ languages, supporting both real-time and batch document translation.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/translator/translator-overview"">Azure Translator Overview</a>","Azure Translator supports 130+ languages for text translation. Capabilities: real-time translation (Translator API), document translation (preserves formatting), custom translation (domain-specific). AI Language (option B) analyzes text but doesn't translate. AI Speech (option C) translates speech audio. Translator features: language detection, transliteration, dictionary lookup, bilingual examples. Custom Translator trains domain-specific models with your terminology. Supports batch translation for large documents maintaining layout/formatting.",AI-900 NLP Translation
"An AI chatbot needs to understand user intents like ""book a flight"", ""cancel reservation"", ""check flight status"" and extract key information like destinations and dates. What Azure capability enables this?<br><br>A) Conversational Language Understanding (CLU)<br>B) Azure AI Translator for language support<br>C) Text Analytics for sentiment only","A) Conversational Language Understanding (CLU). CLU analyzes user utterances to identify intents (what user wants to do) and extract entities (key information like dates, locations, names).<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/language-service/conversational-language-understanding/overview"">CLU Overview</a>","CLU (formerly LUIS) provides: Intent recognition (user's goal), Entity extraction (dates, locations, names), Multiple language support. You define intents and train with example utterances. Translator (option B) only converts languages. Text Analytics sentiment (option C) determines emotion, not intent. CLU returns intent name, confidence score, and extracted entities. Integrates with Azure Bot Service for chatbots. Example: utterance ""Book flight to Paris on May 15"" → Intent: BookFlight, Entities: Destination=Paris, Date=May 15. Requires 10-15 training examples per intent.",AI-900 NLP IntentRecognition
"A document processing application needs to identify and extract names of people, organizations, locations, and dates from contracts. What Azure AI Language capability should be used?<br><br>A) Key phrase extraction for important topics<br>B) Named Entity Recognition (NER) for identifying entities<br>C) Sentiment analysis for document tone","B) Named Entity Recognition (NER) for identifying entities. NER identifies and categorizes named entities in text such as people, organizations, locations, dates, quantities, and other predefined types.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/language-service/named-entity-recognition/overview"">Named Entity Recognition</a>","NER extracts entities with categories: Person, Organization, Location, DateTime, Quantity, PersonType, Event, Product, Skill, Address, Phone, Email, URL, IP address. Returns entity text, category, confidence score. Key phrase extraction (option A) finds important topics but doesn't categorize entities. Sentiment analysis (option C) determines emotion. NER also supports custom entity types. Use cases: contract analysis, content classification, search indexing, PII detection (personally identifiable information). Supports 10+ languages. Part of Azure AI Language service.",AI-900 NLP EntityRecognition
"Customer service managers want to automatically determine if customer emails are positive, negative, or neutral. Which Azure AI Language feature should they use?<br><br>A) Language detection to identify the email language<br>B) Sentiment analysis to determine emotional tone<br>C) Key phrase extraction to find main topics","B) Sentiment analysis to determine emotional tone. Sentiment analysis evaluates text and returns sentiment labels (positive, negative, neutral, mixed) with confidence scores for the overall document and individual sentences.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/language-service/sentiment-opinion-mining/overview"">Sentiment Analysis</a>","Sentiment analysis outputs: Document-level sentiment (overall tone), Sentence-level sentiment (granular analysis), Confidence scores (0-1 for each sentiment). Also provides opinion mining (aspect-based sentiment). Language detection (option A) identifies language but not sentiment. Key phrases (option C) extract topics, not emotion. Use cases: customer feedback analysis, social media monitoring, brand reputation. Supports 100+ languages. Returns positive/negative/neutral/mixed. Works on various text types: reviews, tweets, emails, support tickets.",AI-900 NLP SentimentAnalysis
"A voice assistant application needs to convert spoken user commands into text for processing. What Azure AI Speech capability is required?<br><br>A) Speech-to-text for speech recognition<br>B) Text-to-speech for speech synthesis<br>C) Speech translation for language conversion","A) Speech-to-text for speech recognition. Speech-to-text (speech recognition) converts spoken audio into text, enabling voice commands, transcription, and voice-enabled applications.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-to-text"">Speech-to-Text Overview</a>","Speech-to-text transcribes audio to text. Supports 100+ languages, real-time and batch transcription. Features: speaker diarization (who spoke when), custom models for domain terminology, profanity filtering, punctuation. Text-to-speech (option B) does the opposite (text→audio). Speech translation (option C) converts between languages. Use cases: voice assistants, meeting transcription, call center analytics, accessibility (captions). Custom Speech improves accuracy for accents, background noise, specialized vocabulary. Supports streaming for real-time scenarios.",AI-900 Speech SpeechToText
"A mobile app needs to read text content aloud to users with visual impairments. Which Azure AI Speech capability should be implemented?<br><br>A) Speech-to-text to convert audio to text<br>B) Text-to-speech to synthesize spoken audio<br>C) Custom Neural Voice for unique voice creation","B) Text-to-speech to synthesize spoken audio. Text-to-speech (TTS) converts written text into natural-sounding spoken audio, enabling applications to ""speak"" content to users.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/speech-service/text-to-speech"">Text-to-Speech Overview</a>","Text-to-speech generates audio from text. Features: Neural voices (natural-sounding), 100+ languages and voices, SSML (Speech Synthesis Markup Language) for pronunciation/prosody control, custom voices. Speech-to-text (option A) is the reverse direction. Custom Neural Voice (option C) creates unique branded voices but requires significant data. Use cases: accessibility, audiobooks, navigation apps, IVR systems. SSML controls: speaking rate, pitch, volume, emphasis, pauses, pronunciation. Standard vs Neural voices: Neural sound more natural. Real-time and long-form audio synthesis supported.",AI-900 Speech TextToSpeech
"What type of AI model generates new content like text, images, or code based on learned patterns from training data?<br><br>A) Discriminative model that classifies existing data<br>B) Generative model that creates new content<br>C) Interpretive model that explains data patterns","B) Generative model that creates new content. Generative AI models learn patterns from training data and use that knowledge to create new, original content including text, images, code, and other media.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models"">Generative AI Models</a>","Generative AI creates new content vs. discriminative AI which classifies/predicts. Types of generative models: GPT (text generation), DALL-E (image generation), Codex (code generation), stable diffusion (images). Based on Transformer architecture. Discriminative models (option A) categorize existing data. Interpretive models (option C) aren't a standard AI category. Generative AI capabilities: content creation, conversation, summarization, code completion, translation. Foundation models (large-scale pretrained models) enable few-shot/zero-shot learning. Examples: ChatGPT, GPT-4, Copilot.",AI-900 GenerativeAI Concepts
"Which neural network architecture is the foundation for modern large language models like GPT and enables them to understand context through attention mechanisms?<br><br>A) Convolutional Neural Networks (CNN)<br>B) Transformer architecture<br>C) Recurrent Neural Networks (RNN)","B) Transformer architecture. Transformers use self-attention mechanisms to process sequences in parallel, understanding relationships between words regardless of distance, making them ideal for language models.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-4-models"">Transformer Models</a>","Transformer introduced in ""Attention is All You Need"" paper (2017). Key component: self-attention mechanism weighs importance of different words in context. Processes entire sequence in parallel (vs sequential RNN processing). CNNs (option A) excel at spatial patterns in images. RNNs (option C) were previous standard for sequences but slower. Transformers power: GPT (decoder-only), BERT (encoder-only), T5 (encoder-decoder). Enables large language models (billions of parameters). Attention mechanism allows model to focus on relevant context when generating each word.",AI-900 GenerativeAI Transformers
"A company wants to use generative AI but needs to ensure it doesn't generate harmful, biased, or inappropriate content. Which responsible AI consideration is most critical?<br><br>A) Maximizing model size for better performance<br>B) Implementing content filtering and moderation<br>C) Reducing inference latency for faster responses","B) Implementing content filtering and moderation. Content filtering detects and blocks harmful content (hate speech, violence, self-harm, sexual content) in both prompts and outputs, ensuring responsible AI usage.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/content-filter"">Content Filtering</a>","Responsible generative AI includes: Content filtering (harmful content detection), Groundedness checks (factual accuracy), Bias mitigation, Transparency (disclosing AI use), Human oversight. Model size (option A) doesn't ensure safety. Latency (option C) is performance, not safety. Azure OpenAI includes built-in content filters: severity levels (safe, low, medium, high), customizable thresholds, applies to prompts and completions. Categories: hate, sexual, violence, self-harm. Additional safeguards: jailbreak detection, protected material detection, prompt shields against attacks.",AI-900 GenerativeAI ResponsibleAI
"What Azure service provides access to OpenAI models like GPT-4 and DALL-E with enterprise-grade security and compliance?<br><br>A) Azure OpenAI Service<br>B) Azure Machine Learning<br>C) Azure AI Language","A) Azure OpenAI Service. Azure OpenAI provides REST API access to OpenAI's powerful models with Azure's security, compliance, and regional availability.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/openai/overview"">Azure OpenAI Service Overview</a>","Azure OpenAI includes: GPT-4/GPT-3.5 (text generation), GPT-4V (vision), DALL-E (image generation), Whisper (speech-to-text), text-embedding models. Benefits over OpenAI directly: private endpoints, managed identity, regional deployment, SLA, compliance (HIPAA, SOC 2), content filtering, abuse monitoring. Azure ML (option B) trains custom models. AI Language (option C) is for prebuilt NLP tasks. Features: chat completion API, streaming responses, function calling, fine-tuning, prompt engineering. Use cases: chatbots, content generation, code assistance, summarization, translation.",AI-900 GenerativeAI AzureOpenAI
"In Azure AI Foundry, what is the primary purpose of the model catalog?<br><br>A) To store your organization's private datasets<br>B) To provide access to various pretrained AI models for deployment<br>C) To train custom models from scratch","B) To provide access to various pretrained AI models for deployment. The model catalog is a curated collection of foundation models and open-source models from Microsoft, OpenAI, Hugging Face, and other providers that you can evaluate and deploy.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-studio/how-to/model-catalog-overview"">Model Catalog Overview</a>","Azure AI Foundry (formerly Azure AI Studio) model catalog includes: OpenAI models (GPT-4, GPT-3.5, DALL-E), open-source models (Llama, Mistral, Phi), Azure AI models (language, vision, speech). Features: model comparison, evaluation playground, deployment options, license information. Datasets (option A) are stored elsewhere. Training from scratch (option C) is done in Azure ML. Model catalog enables: quick experimentation, comparing models, fine-tuning pretrained models, deploying to endpoints. Filter by task (chat, embeddings, vision), provider, license. Supports both managed compute and serverless API deployments.",AI-900 GenerativeAI ModelCatalog
"What Azure AI Foundry capability allows you to orchestrate complex AI workflows that chain together models, prompts, and custom code?<br><br>A) Model deployments for serving models<br>B) Prompt flow for designing AI workflows<br>C) Datasets for storing training data","B) Prompt flow for designing AI workflows. Prompt flow provides a visual designer and SDK for building, testing, and deploying AI applications by orchestrating LLMs, prompts, Python code, and Azure AI services into workflows.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-studio/how-to/prompt-flow"">Prompt Flow Overview</a>","Prompt flow enables: Visual DAG (directed acyclic graph) workflow design, Connecting LLM calls with prompts, Integrating custom Python/code, Chaining multiple steps, Testing and debugging, Evaluation with metrics, Version control, Deployment to endpoints. Model deployments (option A) serve individual models. Datasets (option C) store data. Prompt flow use cases: RAG (retrieval augmented generation), question answering with context, multi-step reasoning, integration with external APIs. Built-in tracing for debugging. Supports collaborative development and CI/CD integration.",AI-900 GenerativeAI PromptFlow
"A generative AI application frequently produces factually incorrect information (hallucinations). Which technique helps ground responses in your organization's data?<br><br>A) Increasing model temperature for more creative responses<br>B) Implementing Retrieval Augmented Generation (RAG)<br>C) Fine-tuning the model with historical conversations","B) Implementing Retrieval Augmented Generation (RAG). RAG retrieves relevant information from your data sources and includes it in the prompt context, grounding the model's responses in factual data.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview"">RAG Overview</a>","RAG pattern: 1) User query → 2) Retrieve relevant docs from knowledge base → 3) Include docs in prompt context → 4) LLM generates grounded response. Reduces hallucinations by providing factual context. Higher temperature (option A) increases creativity but worsens accuracy. Fine-tuning (option C) is expensive and requires retraining. RAG benefits: up-to-date information, citeable sources, no retraining needed, works with proprietary data. Typically uses Azure AI Search for retrieval with vector/semantic search. Combine with prompt engineering (""answer only using provided context"").",AI-900 GenerativeAI RAG
"What Azure service helps detect and extract structured information from forms and documents including invoices, receipts, and identity documents?<br><br>A) Azure AI Vision for general image analysis<br>B) Azure AI Document Intelligence for form processing<br>C) Azure AI Language for text analysis","B) Azure AI Document Intelligence for form processing. Document Intelligence (formerly Form Recognizer) extracts text, key-value pairs, tables, and structure from documents using OCR and machine learning.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/overview"">Document Intelligence Overview</a>","Document Intelligence provides: Prebuilt models (invoices, receipts, IDs, tax forms, health insurance cards), Custom models (train on your forms), Layout model (tables, structure), Read model (OCR). Extracts structured data with confidence scores. AI Vision (option A) has OCR but doesn't understand form structure. AI Language (option C) analyzes text, not documents. Use cases: invoice processing, receipt digitization, identity verification, contract management. Outputs JSON with extracted fields. Supports batch processing, Custom models need 5-10 training documents.",AI-900 DocumentIntelligence FormProcessing
"A self-driving car uses cameras to identify objects like pedestrians, vehicles, and traffic signs in real-time. What type of deep learning model is most suitable?<br><br>A) Recurrent Neural Networks for sequence processing<br>B) Convolutional Neural Networks for image recognition<br>C) Transformer models for language understanding","B) Convolutional Neural Networks for image recognition. CNNs are specialized neural networks designed to process grid-like data (images) by detecting spatial hierarchies and patterns through convolutional layers.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-deep-learning-vs-machine-learning"">Deep Learning Concepts</a>","CNNs excel at computer vision: image classification, object detection, segmentation. Architecture: convolutional layers (feature extraction), pooling layers (dimensionality reduction), fully connected layers (classification). RNNs (option A) handle sequential data (text, time-series). Transformers (option C) dominate NLP but are newer to vision (Vision Transformers). CNN advantages: translation invariance, parameter sharing, automatic feature learning. Famous architectures: ResNet, VGG, Inception, YOLO (object detection). CNNs detect edges → shapes → objects hierarchically. Requires labeled training data (supervised learning).",AI-900 DeepLearning CNN
"What is the main advantage of using pretrained foundation models compared to training models from scratch?<br><br>A) Foundation models require less computational resources and data for adaptation<br>B) Foundation models are smaller and faster than custom models<br>C) Foundation models don't require any fine-tuning","A) Foundation models require less computational resources and data for adaptation. Pretrained foundation models leverage knowledge learned from massive datasets, enabling effective task adaptation with minimal data through fine-tuning, prompt engineering, or few-shot learning.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-foundation-models"">Foundation Models</a>","Foundation models are pretrained on massive datasets (billions of parameters, terabytes of data). Benefits: transfer learning (knowledge reuse), few-shot learning (learn from examples), zero-shot learning (no task-specific training), reduced training cost/time. Foundation models (option B) are actually very large (GPT-4: 1T+ parameters). Some tasks need fine-tuning (option C). Examples: GPT-4, BERT, CLIP, SAM. Training from scratch costs millions and months. Foundation models enable democratization of AI. Adaptation techniques: prompt engineering, fine-tuning, RAG.",AI-900 GenerativeAI FoundationModels
"In a machine learning classification model, what does ""precision"" measure?<br><br>A) The percentage of all correct predictions<br>B) Of predictions labeled positive, what percentage were actually positive<br>C) Of all actual positive cases, what percentage were correctly identified","B) Of predictions labeled positive, what percentage were actually positive. Precision measures the accuracy of positive predictions: Precision = True Positives / (True Positives + False Positives).<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml-metrics"">Classification Metrics</a>","Precision = TP/(TP+FP) answers: ""When model says positive, is it correct?"". High precision = few false positives. Accuracy (option A) = (TP+TN)/Total. Recall (option C) = TP/(TP+FN) answers: ""Of actual positives, how many found?"". Example: Spam detection with high precision rarely marks legitimate emails as spam (few false positives). Trade-off: High precision often means lower recall. F1-score balances both. Use precision when false positives are costly. Confusion matrix shows TP, TN, FP, FN for full picture.",AI-900 MachineLearning Metrics
"What is ""overfitting"" in machine learning?<br><br>A) Model performs well on training data but poorly on new data<br>B) Model performs poorly on both training and test data<br>C) Model training takes too long to complete","A) Model performs well on training data but poorly on new data. Overfitting occurs when a model learns training data too well, including noise and peculiarities, failing to generalize to unseen data.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-train-machine-learning-model#overfitting-and-underfitting"">Overfitting Concepts</a>","Overfitting: model memorizes training data instead of learning patterns. Signs: high training accuracy but low validation accuracy. Causes: too complex model, insufficient training data, too many features, too many training epochs. Poor performance on both (option B) is underfitting. Training time (option C) is unrelated. Prevention techniques: regularization (L1, L2), dropout, early stopping, cross-validation, more training data, simpler model architecture. Sweet spot: model complex enough to learn patterns but simple enough to generalize. Monitor validation loss during training to detect overfitting early.",AI-900 MachineLearning Overfitting
"Which Azure service provides prebuilt AI capabilities like speech-to-text, text-to-speech, translation, and vision without requiring machine learning expertise?<br><br>A) Azure Cognitive Services (Azure AI Services)<br>B) Azure Machine Learning for custom model training<br>C) Azure Databricks for data science workloads","A) Azure Cognitive Services (Azure AI Services). Cognitive Services provides prebuilt, pretrained AI models accessible via REST APIs and SDKs, enabling developers to add AI capabilities without ML expertise.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/what-are-ai-services"">Azure AI Services Overview</a>","Azure AI Services (formerly Cognitive Services) includes: Vision (image analysis, Face, Custom Vision), Language (text analytics, translation, CLU, QnA), Speech (STT, TTS, translation), Decision (Anomaly Detector, Content Safety), OpenAI. Benefits: prebuilt models, simple API calls, no training required, scalable, multi-service resources. Azure ML (option B) requires ML expertise for custom models. Databricks (option C) is for data engineering/science. Pricing: pay-per-transaction or commitment tiers. Free tiers available for testing. Single resource can access multiple APIs.",AI-900 AzureAI CognitiveServices
"An AI solution needs to analyze images to determine if they contain inappropriate content. Which Azure service provides content moderation capabilities?<br><br>A) Azure AI Vision for general image analysis<br>B) Azure Content Safety for detecting harmful content<br>C) Custom Vision for training moderation models","B) Azure Content Safety for detecting harmful content. Azure Content Safety (formerly Content Moderator) analyzes text and images for offensive, risky, or undesirable content across multiple categories.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/content-safety/overview"">Content Safety Overview</a>","Content Safety detects: Hate (discrimination, slurs), Sexual (explicit content), Violence (gore, weapons), Self-harm content. Multi-severity levels (safe, low, medium, high). Supports text and images. AI Vision (option A) has basic adult content flags but Content Safety is specialized. Custom Vision (option C) requires training data. Content Safety provides: real-time API, severity scores, customizable thresholds, blocklists for custom terms. Use cases: user-generated content platforms, comment moderation, image uploads, gaming chat. Includes groundedness detection and protected material detection for LLMs.",AI-900 ContentModeration Safety
"A healthcare company needs to ensure their AI solution maintains patient data privacy and complies with regulations. Which responsible AI principle is most relevant?<br><br>A) Fairness in treating all patients equally<br>B) Privacy and security of sensitive data<br>C) Transparency in explaining AI decisions","B) Privacy and security of sensitive data. The privacy and security principle ensures AI systems protect sensitive information, comply with regulations (HIPAA, GDPR), and implement proper data governance.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai"">Microsoft Responsible AI Principles</a>","Privacy and security includes: data encryption (at rest, in transit), access control (RBAC), compliance certifications, anonymization/de-identification, audit logging, secure model deployment. Fairness (option A) prevents bias. Transparency (option C) explains decisions. Privacy measures: Use Confidential Computing, encrypt models, implement data minimization (use only necessary data), obtain informed consent, provide data deletion capabilities. Azure AI Services offer private endpoints, VNet integration, customer-managed keys. Consider differential privacy for training data protection.",AI-900 ResponsibleAI Privacy
"What is the purpose of ""temperature"" parameter in generative AI models?<br><br>A) Controls the length of generated responses<br>B) Controls randomness and creativity in outputs<br>C) Controls the model's processing speed","B) Controls randomness and creativity in outputs. Temperature (0.0-1.0+) controls output randomness: lower values produce deterministic, focused responses; higher values increase creativity and variety.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/completions"">Model Parameters</a>","Temperature affects probability distribution: Temperature = 0: deterministic (always same output), Temperature = 0.3-0.5: focused, consistent, Temperature = 0.7-0.9: creative, diverse, Temperature = 1.0+: highly random. Length (option A) is controlled by max_tokens. Speed (option C) is unrelated. Other parameters: top_p (nucleus sampling), frequency_penalty (reduce repetition), presence_penalty (encourage new topics). Use low temperature for: factual Q&A, code generation, structured tasks. Use high temperature for: creative writing, brainstorming, varied outputs. Temperature = 0 is deterministic but not always identical (due to non-deterministic GPU operations).",AI-900 GenerativeAI Parameters
"A retail company wants to forecast monthly sales based on historical data. What type of machine learning task is this?<br><br>A) Time-series forecasting<br>B) Clustering for pattern discovery<br>C) Classification of sales categories","A) Time-series forecasting. Time-series forecasting predicts future numerical values based on historical sequential data where time order matters, ideal for sales, demand, and trend prediction.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml#time-series-forecasting"">Time-Series Forecasting</a>","Time-series forecasting handles temporal dependencies (past influences future). Features: seasonality detection, trend analysis, multiple time steps ahead. Algorithms: ARIMA, Prophet, LSTM networks. Clustering (option B) groups data without time dimension. Classification (option C) predicts categories, not continuous values. Specific to forecasting: lagged features (previous values), rolling aggregates (moving averages), date features (day of week, month). AutoML supports time-series forecasting with automatic feature engineering. Validation uses time-based splits (train on past, test on future). Use cases: demand forecasting, inventory planning, financial predictions, energy load forecasting.",AI-900 MachineLearning Forecasting
"What is the main advantage of using Azure Machine Learning compute clusters for model training?<br><br>A) Automatically scales compute resources up and down based on workload<br>B) Provides free unlimited compute for all users<br>C) Requires no configuration or setup","A) Automatically scales compute resources up and down based on workload. Azure ML compute clusters automatically scale from 0 to multiple nodes based on submitted jobs, optimizing cost by shutting down when idle.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-attach-compute-cluster"">Compute Clusters</a>","Compute clusters provide: auto-scaling (0 to max nodes), job scheduling and queuing, multi-node distributed training, choice of VM sizes (CPU/GPU), automatic setup. Not free (option B) - pay for what you use. Requires some configuration (option C): min/max nodes, VM type, idle time before scale down. Benefits: cost-effective (scale to zero), supports large experiments, parallel job execution. Types: compute cluster (training), compute instance (development), inference cluster (deployment). Alternatives: local compute (small experiments), compute instance (interactive), attached compute (existing VMs). Choose GPU VMs for deep learning.",AI-900 AzureML ComputeClusters
"An AI chatbot needs to answer questions using information from your company's internal documentation. Which approach is most effective?<br><br>A) Fine-tune a language model on all company documents<br>B) Use RAG to retrieve relevant docs and provide them as context<br>C) Create a classification model to categorize questions","B) Use RAG to retrieve relevant docs and provide them as context. RAG (Retrieval Augmented Generation) searches your knowledge base, retrieves relevant documents, and includes them in the prompt, enabling accurate answers grounded in your data.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview"">RAG Pattern</a>","RAG workflow: 1) User asks question, 2) Embed question as vector, 3) Search document index (Azure AI Search), 4) Retrieve top-k relevant docs, 5) Inject docs into prompt context, 6) LLM generates answer from context. Benefits over fine-tuning (option A): no retraining needed, works with updated documents immediately, more cost-effective, easier to maintain, provides source citations. Classification (option C) doesn't generate answers. RAG architecture: document indexing phase (chunk docs, create embeddings, store in vector DB), query phase (embed query, semantic/vector search, prompt LLM). Combine with semantic ranking for best results.",AI-900 GenerativeAI RAG
"What Azure AI service would you use to create a custom image classification model without writing code?<br><br>A) Azure AI Vision for prebuilt image analysis<br>B) Azure Custom Vision for training custom models<br>C) Azure Machine Learning for advanced model building","B) Azure Custom Vision for training custom models. Custom Vision provides a user-friendly web interface for training custom image classification and object detection models by uploading and labeling images.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/custom-vision-service/overview"">Custom Vision Overview</a>","Custom Vision enables: no-code model training via portal, upload images and tag them, automatic model training, evaluation metrics, model export (TensorFlow, ONNX, CoreML), REST API and SDK. AI Vision (option A) only provides prebuilt capabilities. Azure ML (option C) requires more ML expertise. Custom Vision supports: image classification (assign labels), object detection (bounding boxes), requires 5-50+ images per tag. Quick training (<5 min) or advanced training (longer, better accuracy). Provides precision/recall metrics. Export models for edge deployment. Iterations track model versions.",AI-900 ComputerVision CustomVision
"A conversational AI bot needs to remember context from earlier in the conversation when responding to follow-up questions. How should this be implemented?<br><br>A) Send only the latest user message to the model<br>B) Maintain conversation history and include it in each request<br>C) Train a separate model for each conversation","B) Maintain conversation history and include it in each request. To preserve context, include previous messages (conversation history) in the prompt/messages array, allowing the model to understand references and maintain coherent dialogue.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt"">Chat Completion API</a>","Conversation pattern: maintain messages array with roles (system, user, assistant). Each API call includes: system message (instructions), conversation history (past turns), new user message. Single message (option A) loses context. Separate models (option C) is impractical. Implementation: store messages in session state or database, include in each request, manage token limits (remove old messages/summarize). System message sets behavior (""You are a helpful assistant""). Token management: track cumulative tokens, implement sliding window or summarization. Balance context retention with token limits (GPT-3.5: 4K, GPT-4: 8K-128K tokens).",AI-900 GenerativeAI Conversation
"What is the primary purpose of A/B testing in machine learning deployments?<br><br>A) To debug errors in model code<br>B) To compare performance between two model versions with real traffic<br>C) To train models faster using parallel processing","B) To compare performance between two model versions with real traffic. A/B testing splits live traffic between models (e.g., 90% to current model, 10% to new model) to compare real-world performance before full deployment.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-online-endpoints#deploy-and-debug-locally-using-local-endpoints"">ML Deployments</a>","A/B testing (champion/challenger testing) safely validates new models: Route traffic percentage to each variant, Monitor metrics (accuracy, latency, errors), Gradually increase new model traffic if better, Roll back if worse. Debugging (option A) done pre-deployment. Parallel training (option C) is different. Azure ML managed endpoints support traffic splitting across deployments. Key metrics: model accuracy, response time, error rate, business outcomes (conversion, revenue). Canary deployment: start 5-10% traffic, gradually increase. Blue-green deployment: maintain two environments, switch when ready. Minimizes risk of deploying inferior models.",AI-900 MachineLearning ABTesting
"Which factor most significantly impacts the quality of a machine learning model?<br><br>A) The color scheme of the training interface<br>B) The quality and quantity of training data<br>C) The speed of the developer's computer","B) The quality and quantity of training data. Model quality fundamentally depends on training data: representative samples, accurate labels, sufficient volume, and diversity ensure the model learns correct patterns.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-data"">Data Concepts in ML</a>","Training data quality principles: representative (covers real-world scenarios), balanced (sufficient examples per class), accurate labels, diverse (various conditions), sufficient quantity. Poor data = poor model regardless of algorithm. Color scheme (option A) is irrelevant. Computer speed (option C) affects training time, not quality. Data issues: imbalanced classes, label errors, missing values, outliers, bias. Data preparation: cleaning, normalization, feature engineering, augmentation. Rule of thumb: deep learning needs 1000s-millions of examples, traditional ML needs 100s-1000s. ""Garbage in, garbage out"" - no algorithm overcomes bad data.",AI-900 MachineLearning DataQuality
"What Azure service helps index and search large volumes of documents to enable knowledge mining and information retrieval?<br><br>A) Azure Blob Storage for document storage<br>B) Azure AI Search for intelligent search capabilities<br>C) Azure SQL Database for structured queries","B) Azure AI Search for intelligent search capabilities. Azure AI Search (formerly Cognitive Search) provides full-text search, semantic search, vector search, and AI enrichment for unstructured data.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/search/search-what-is-azure-search"">Azure AI Search Overview</a>","Azure AI Search features: full-text search, vector search (embeddings), semantic search (relevance), AI enrichment (OCR, entity extraction, key phrases), faceted navigation, auto-complete, geo-search. Blob Storage (option A) only stores files. SQL Database (option C) is for structured data. AI Search capabilities: index documents from various sources, apply skillsets (AI enrichment pipeline), semantic ranking, knowledge store projections. Use cases: enterprise search, e-commerce product search, document discovery, knowledge mining. Supports 50+ languages. Integrates with Azure AI services for content extraction and analysis.",AI-900 Search KnowledgeMining
"A speech-enabled application needs to work in noisy environments and recognize industry-specific terminology accurately. What Azure Speech capability improves accuracy?<br><br>A) Neural text-to-speech voices<br>B) Custom Speech model trained with domain audio<br>C) Speech translation to other languages","B) Custom Speech model trained with domain audio. Custom Speech allows training models with your specific audio recordings and transcripts, improving accuracy for specialized terminology, accents, and acoustic environments.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/speech-service/custom-speech-overview"">Custom Speech Overview</a>","Custom Speech improves recognition for: domain-specific terms (medical, legal, technical), accents and dialects, noisy environments (factory, call center), branded product names. Training data: audio + human transcripts (most effective), plain text (for vocabulary), pronunciation data. Neural TTS (option A) is for speech synthesis. Translation (option C) doesn't improve recognition accuracy. Base model WER (Word Error Rate) ~15-20%, custom model WER ~5-10% for domain. Minimum data: 1-10 hours audio recommended. Portal provides evaluation metrics comparing base vs custom models. Deploy custom models to speech endpoints.",AI-900 Speech CustomSpeech
"What responsible AI principle requires that users be informed when they are interacting with an AI system?<br><br>A) Fairness to ensure equal treatment<br>B) Transparency to disclose AI usage<br>C) Accountability for system decisions","B) Transparency to disclose AI usage. Transparency includes being open about AI system use, capabilities, limitations, and when users are interacting with AI versus humans.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai"">Responsible AI Principles</a>","Transparency encompasses: disclosing AI interaction (""This is a bot""), explaining how system works, providing confidence scores, acknowledging limitations, documenting data sources. Fairness (option A) addresses bias. Accountability (option C) assigns responsibility. Transparency requirements: AI disclosure in interfaces, model cards documenting performance, explainability for decisions (""loan denied because...""), data transparency (sources, bias), limitation disclosure (""I'm an AI, may make errors""). Builds trust and enables informed consent. EU AI Act and other regulations require transparency. Don't mislead users about AI capabilities or present AI as human.",AI-900 ResponsibleAI Transparency
"An image recognition model correctly identifies 850 out of 1000 test images. What is the model's accuracy?<br><br>A) 15%<br>B) 85%<br>C) 850%","B) 85%. Accuracy is the percentage of correct predictions: (850 correct / 1000 total) × 100 = 85% accuracy.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml-metrics#classification-metrics"">Classification Metrics</a>","Accuracy = Correct Predictions / Total Predictions = (TP + TN) / (TP + TN + FP + FN). Simple metric but can be misleading with imbalanced classes. Example: 95% accuracy detecting rare disease sounds good but useless if model predicts ""no disease"" for everyone in 95% healthy dataset. Better metrics for imbalanced data: precision, recall, F1-score, AUC-ROC. Accuracy works well for balanced class distributions. Other metrics: balanced accuracy (average of recall per class), top-k accuracy (correct prediction in top k guesses). Always consider confusion matrix for full picture of classification performance.",AI-900 MachineLearning Accuracy
"What is the primary purpose of ""prompt engineering"" in generative AI?<br><br>A) Training the model with new data<br>B) Crafting effective input instructions to get desired outputs<br>C) Optimizing model infrastructure and deployment","B) Crafting effective input instructions to get desired outputs. Prompt engineering designs and refines prompts (input text) to guide model behavior, improve output quality, and achieve specific goals without model retraining.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering"">Prompt Engineering</a>","Prompt engineering techniques: clear instructions (""Act as an expert...""), provide context, specify output format (""Return JSON""), use examples (few-shot learning), break complex tasks into steps, include constraints (""Answer in 50 words""), system messages for behavior. Training (option A) modifies model weights. Infrastructure (option C) is deployment engineering. Good prompts: specific, clear, well-structured, include examples, set constraints. Prompt patterns: zero-shot (no examples), one-shot (1 example), few-shot (3-5 examples), chain-of-thought (show reasoning). Iterate and test prompt variations. Temperature and other parameters also affect output.",AI-900 GenerativeAI PromptEngineering
"What Azure Machine Learning feature automatically selects features, algorithms, and hyperparameters to find the best model?<br><br>A) Manual model training with custom code<br>B) Automated Machine Learning (AutoML)<br>C) Azure AI services prebuilt models","B) Automated Machine Learning (AutoML). AutoML automates the iterative process of model development by trying multiple algorithms, preprocessing techniques, and hyperparameters to find the optimal model.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml"">AutoML Overview</a>","AutoML automates: data preprocessing, feature engineering, algorithm selection (tries 10s of algorithms), hyperparameter tuning, model evaluation, ensemble creation. Manual training (option A) requires expertise and time. Prebuilt models (option C) aren't customizable. AutoML supports: classification, regression, time-series forecasting, NLP, computer vision. Handles imbalanced data, missing values, categorical encoding. Provides: best model, leaderboard of all models tried, explanations for best model. Configurable: time limit, metric to optimize (accuracy, AUC, RMSE), iterations, validation strategy. Saves weeks of experimentation. Output: trained model ready for deployment.",AI-900 AzureML AutoML
"Which scenario best demonstrates a classification machine learning task?<br><br>A) Predicting tomorrow's temperature in degrees<br>B) Determining if an email is spam or not spam<br>C) Grouping customers by purchasing patterns without labels","B) Determining if an email is spam or not spam. Classification assigns data to predefined categories. Binary classification (spam/not spam) has two classes; multiclass has 3+.<br><br>Reference: <a href=""https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml#classification"">Classification Overview</a>","Classification characteristics: predicts discrete categories, requires labeled training data (supervised learning), outputs class and confidence score. Temperature prediction (option A) is regression (numeric output). Grouping without labels (option C) is clustering (unsupervised). Classification examples: spam detection, disease diagnosis (positive/negative), image recognition (cat/dog/bird), sentiment (positive/negative/neutral), fraud detection. Algorithms: logistic regression, decision trees, random forest, SVM, neural networks. Evaluation: accuracy, precision, recall, F1, ROC-AUC. Binary classification: 2 classes. Multiclass: 3+ mutually exclusive classes. Multilabel: multiple labels per instance.",AI-900 MachineLearning Classification